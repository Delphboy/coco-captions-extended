accelerate==1.9.0
av==15.0.0
certifi==2025.8.3
charset-normalizer==3.4.2
einops==0.8.1
filelock==3.13.1
flash_attn==2.8.2
fsspec==2024.6.1
hf-xet==1.1.5
huggingface-hub==0.34.3
idna==3.10
inquirerpy==0.3.4
Jinja2==3.1.4
MarkupSafe==2.1.5
mlx-cuda==0.27.1
mpmath==1.3.0
networkx==3.3
numpy==2.1.2
nvidia-cublas-cu11==11.11.3.6
nvidia-cublas-cu12==12.9.1.4
nvidia-cuda-cupti-cu11==11.8.87
nvidia-cuda-nvrtc-cu11==11.8.89
nvidia-cuda-nvrtc-cu12==12.9.86
nvidia-cuda-runtime-cu11==11.8.89
nvidia-cudnn-cu11==9.1.0.70
nvidia-cudnn-cu12==9.11.0.98
nvidia-cufft-cu11==10.9.0.58
nvidia-curand-cu11==10.3.0.86
nvidia-cusolver-cu11==11.4.1.48
nvidia-cusparse-cu11==11.7.5.86
nvidia-nccl-cu11==2.21.5
nvidia-nvtx-cu11==11.8.86
packaging==25.0
pfzy==0.3.4
pillow==11.0.0
prompt_toolkit==3.0.51
psutil==7.0.0
PyYAML==6.0.2
qwen-vl-utils==0.0.11
regex==2025.7.34
requests==2.32.4
safetensors==0.5.3
setuptools==70.2.0
sympy==1.13.3
tokenizers==0.21.4
torch==2.7.1+cu118
torchaudio==2.7.1+cu118
torchvision==0.22.1+cu118
tqdm==4.67.1
transformers @ git+https://github.com/huggingface/transformers@2a9febd632dde21d3f873ebce176d2ac4edc24b8
triton==3.3.1
typing_extensions==4.12.2
urllib3==2.5.0
wcwidth==0.2.13
wheel==0.45.1
